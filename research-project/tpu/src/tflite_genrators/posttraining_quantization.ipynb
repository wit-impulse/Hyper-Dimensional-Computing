{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "posttraining_quantization.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "_TZTwG7nhm0C"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jfdLMZb_zXe"
      },
      "source": [
        "import logging\n",
        "logging.getLogger(\"tensorflow\").setLevel(logging.DEBUG)\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "assert float(tf.__version__[:3]) >= 2.3"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_U9SR5dvXgJ"
      },
      "source": [
        "# Load MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV4IrcNnvbzM"
      },
      "source": [
        "# Normalize the input image so that each pixel value is between 0 to 1.\n",
        "train_images = train_images.astype(np.float32) / 255.0\n",
        "test_images = test_images.astype(np.float32) / 255.0"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYY8hPA47BZy"
      },
      "source": [
        "# One-hot encode the labels\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels, 10)\n",
        "#y_valid = tf.keras.utils.to_categorical(y_valid, 10)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, 10)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWVs1EPwOJ2z"
      },
      "source": [
        "# ----------------------------------------CNN1-UNCOMMENT BELOW CODE-------------------------------------------------------------\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.InputLayer(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "\n",
        "  tf.keras.layers.Conv2D(filters=64, kernel_size=(2,2), padding='same', activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "  tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "  tf.keras.layers.Conv2D(filters=32, kernel_size=(2,2), padding='same', activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "  tf.keras.layers.Dropout(0.3),\n",
        "\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "#-----------------------------------------------CNN2-UNCOMMENT BELOW CODE----------------------------------------------------------\n",
        "\n",
        "# model = tf.keras.Sequential()\n",
        "\n",
        "# model.add(tf.keras.layers.InputLayer(input_shape=(28, 28)))\n",
        "# model.add(tf.keras.layers.Reshape(target_shape=(28, 28, 1)))\n",
        "# model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "# model.add(tf.keras.layers.BatchNormalization())\n",
        "# model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'))       \n",
        "# model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "# model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "# model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
        "# model.add(tf.keras.layers.BatchNormalization()),\n",
        "# model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
        "# model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "# model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "# model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
        "# tf.keras.layers.BatchNormalization(),\n",
        "# model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
        "# model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "# model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "# model.add(tf.keras.layers.Flatten())\n",
        "# model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "# model.add(tf.keras.layers.Dropout(0.4))\n",
        "# model.add(tf.keras.layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZbUZIf9wNl6"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zMsiCjOzsdP",
        "outputId": "9ed6ae73-511b-4093-cdee-00928b500a25"
      },
      "source": [
        "# Train the digit classification model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=1\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 85s 45ms/step - loss: 0.5425 - accuracy: 0.8031\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc26d492c10>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ND0_xLKpAT2C",
        "outputId": "b2d6f2c7-e152-4906-e7f2-8b7d95ebcd5e"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "tflite_model = converter.convert()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpafsnry3i/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKaytUWxAbjU",
        "outputId": "8fcb6682-f424-4f71-f9dd-2377d1de5336"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "tflite_model_quant = converter.convert()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp50qsrehg/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp50qsrehg/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pi1RmqQoArbH",
        "outputId": "8f23dcda-8004-49bc-df38-efc22d6a7134"
      },
      "source": [
        "def representative_data_gen():\n",
        "  for input_value in tf.data.Dataset.from_tensor_slices(train_images).batch(1).take(100):\n",
        "    # Model has only one input so each data point has one element.\n",
        "    yield [input_value]\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_data_gen\n",
        "\n",
        "tflite_model_quant = converter.convert()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpoi6bm_d_/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpoi6bm_d_/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AURvE5kHAue_",
        "outputId": "3fed3f7c-c075-4dd9-b6df-4181a074e496"
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_content=tflite_model_quant)\n",
        "input_type = interpreter.get_input_details()[0]['dtype']\n",
        "print('input: ', input_type)\n",
        "output_type = interpreter.get_output_details()[0]['dtype']\n",
        "print('output: ', output_type)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  <class 'numpy.float32'>\n",
            "output:  <class 'numpy.float32'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vzQtqaDBOy8",
        "outputId": "9bc328d0-60bf-4e86-91fe-66a7794d8cf2"
      },
      "source": [
        "def representative_data_gen():\n",
        "  for input_value in tf.data.Dataset.from_tensor_slices(train_images).batch(1).take(100):\n",
        "    yield [input_value]\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_data_gen\n",
        "# Ensure that if any ops can't be quantized, the converter throws an error\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.uint8\n",
        "\n",
        "tflite_model_quant = converter.convert()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpz0t5n9yl/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpz0t5n9yl/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSEFUHudBU0y",
        "outputId": "d84d718f-7c33-4cd2-d923-4d704603e5da"
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_content=tflite_model_quant)\n",
        "input_type = interpreter.get_input_details()[0]['dtype']\n",
        "print('input: ', input_type)\n",
        "output_type = interpreter.get_output_details()[0]['dtype']\n",
        "print('output: ', output_type)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:  <class 'numpy.uint8'>\n",
            "output:  <class 'numpy.uint8'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKyp55rxBXP3",
        "outputId": "9e56c086-05fa-4940-d2bf-3d2dcd35c3fc"
      },
      "source": [
        "import pathlib\n",
        "\n",
        "tflite_models_dir = pathlib.Path(\"fmnist_tflite_models/\")\n",
        "tflite_models_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Save the unquantized/float model:\n",
        "tflite_model_file = tflite_models_dir/\"fmnist_model.tflite\"\n",
        "tflite_model_file.write_bytes(tflite_model)\n",
        "# Save the quantized model:\n",
        "tflite_model_quant_file = tflite_models_dir/\"fmnist_model_quant.tflite\"\n",
        "tflite_model_quant_file.write_bytes(tflite_model_quant)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "421120"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfVeDF7eCyC1"
      },
      "source": [
        "# Helper function to run inference on a TFLite model\n",
        "def run_tflite_model(tflite_file, test_image_indices):\n",
        "  global test_images\n",
        "\n",
        "  # Initialize the interpreter\n",
        "  interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
        "  interpreter.allocate_tensors()\n",
        "\n",
        "  input_details = interpreter.get_input_details()[0]\n",
        "  output_details = interpreter.get_output_details()[0]\n",
        "\n",
        "  predictions = np.zeros((len(test_image_indices),), dtype=int)\n",
        "  for i, test_image_index in enumerate(test_image_indices):\n",
        "    test_image = test_images[test_image_index]\n",
        "    test_label = test_labels[test_image_index]\n",
        "\n",
        "    # Check if the input type is quantized, then rescale input data to uint8\n",
        "    if input_details['dtype'] == np.uint8:\n",
        "      input_scale, input_zero_point = input_details[\"quantization\"]\n",
        "      test_image = test_image / input_scale + input_zero_point\n",
        "\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
        "    interpreter.set_tensor(input_details[\"index\"], test_image)\n",
        "    interpreter.invoke()\n",
        "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
        "\n",
        "    predictions[i] = output.argmax()\n",
        "\n",
        "  return predictions"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALpPUYlXC5RY"
      },
      "source": [
        "import matplotlib.pylab as plt\n",
        "\n",
        "# Change this to test a different image\n",
        "test_image_index = 1\n",
        "\n",
        "## Helper function to test the models on one image\n",
        "def test_model(tflite_file, test_image_index, model_type):\n",
        "  global test_labels\n",
        "\n",
        "  predictions = run_tflite_model(tflite_file, [test_image_index])\n",
        "\n",
        "  plt.imshow(test_images[test_image_index])\n",
        "  template = model_type + \" Model \\n True:{true}, Predicted:{predict}\"\n",
        "  _ = plt.title(template.format(true= str(test_labels[test_image_index]), predict=str(predictions[0])))\n",
        "  plt.grid(False)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWbRoXw6C6jS"
      },
      "source": [
        "test_model(tflite_model_file, test_image_index, model_type=\"Float\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLleLYw-C8wQ"
      },
      "source": [
        "test_model(tflite_model_quant_file, test_image_index, model_type=\"Quantized\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mt11lx_iW2_t"
      },
      "source": [
        "# Load MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.astype(np.float32) / 255.0\n",
        "test_images = test_images.astype(np.float32) / 255.0"
      ],
      "metadata": {
        "id": "mNZuyQMvjgvz"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL42hAMvC_sx"
      },
      "source": [
        "# Helper function to evaluate a TFLite model on all images\n",
        "def evaluate_model(tflite_file, model_type):\n",
        "  global test_images\n",
        "  global test_labels\n",
        "\n",
        "  test_image_indices = range(test_images.shape[0])\n",
        "  predictions = run_tflite_model(tflite_file, test_image_indices)\n",
        "  print(predictions[:50])\n",
        "  accuracy = (np.sum(test_labels== predictions) * 100) / len(test_images)\n",
        "\n",
        "  print('%s model accuracy is %.4f%% (Number of test samples=%d)' % (\n",
        "      model_type, accuracy, len(test_images)))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lo3J3rpDDlz"
      },
      "source": [
        "evaluate_model(tflite_model_file, model_type=\"Float\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbl6YCkhas5R"
      },
      "source": [
        "# buf = open('./fmnist_tflite_models/fmnist_model_quant.tflite', 'rb').read()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOggKRk3DEnl"
      },
      "source": [
        "evaluate_model(tflite_model_quant_file, model_type=\"Quantized\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TZTwG7nhm0C"
      },
      "source": [
        "## Run the model on the Edge TPU\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwywT4ZpQjLf"
      },
      "source": [
        "You can now run the model on your Coral device with acceleration on the Edge TPU.\n",
        "\n",
        "Just follow the instructions on that page to set up your device, copy the `fmnist_model_quant.tflite` and `fmnist_labels.txt` files to your Coral Dev Board or device with a Coral Accelerator like this:\n",
        "\n",
        "```\n",
        "python3 edge_tpu_inference.py \\\n",
        "  --.tflite fmnist_model_quant.tflite\\\n",
        "  --labels fmnist_labels.txt \n",
        "```\n",
        "\n",
        "Check out more examples for running inference at [coral.ai/examples](https://coral.ai/examples/#code-examples/)."
      ]
    }
  ]
}